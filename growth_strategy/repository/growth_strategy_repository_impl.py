import os
import openai
import asyncio
import json

from typing import List, Dict, Any

from langchain_core.callbacks import AsyncCallbackHandler
from langchain_core.outputs import LLMResult
from langchain_community.llms import Ollama
from langchain_core.documents import Document
from growth_strategy.repository.growth_strategy_repository import GrowthStrategyRepository
from langchain_text_splitters import TextSplitter
from langchain_community.document_loaders import TextLoader
from langchain_core.prompts import PromptTemplate
from langchain_community.vectorstores import FAISS
from langchain_core.output_parsers import StrOutputParser
from langchain_openai import ChatOpenAI, OpenAIEmbeddings

from dotenv import load_dotenv
load_dotenv()

openai.api_key = os.getenv("OPENAI_API_KEY")
if not openai.api_key:
    raise ValueError("API Keyê°€ ì¤€ë¹„ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤!")

os.environ["OPENAI_API_KEY"] = openai.api_key
environ = os.getenv("ENV")

class MyCustomAsyncHandler(AsyncCallbackHandler):
    """Async callback handler that can be used to handle callbacks from langchain."""

    async def on_llm_start(
            self, serialized: Dict[str, Any], prompts: List[str], **kwargs: Any
    ) -> None:
        """Run when chain starts running."""
        print("zzzz....")
        await asyncio.sleep(0.1)
        print("Hi! I just woke up. Your llm is starting")

    async def on_llm_end(self, response: LLMResult, **kwargs: Any) -> None:
        """Run when chain ends running."""
        print("zzzz....")
        await asyncio.sleep(0.1)
        print("Hi! I just woke up. Your llm is ending")


class BracketSplitter(TextSplitter):
    def split_text(self, text: str) -> List[str]:
        # '[' ê¸°ì¤€ìœ¼ë¡œ ë¨¼ì € splití•˜ê³ , ê° ë¶€ë¶„ì—ì„œ ']'ë¥¼ ì œê±°í•©ë‹ˆë‹¤.
        chunks = text.split('[')
        return [chunk.replace(']', '').strip() for chunk in chunks if chunk.strip()]

def load_json_data(file_path: str) -> List[Dict[str, Any]]:
    """Loads JSON data from a file."""
    with open(file_path, 'r', encoding="utf-8") as file:
        return json.load(file)

def get_relevant_influencers(user_input: Dict, vectorstore: FAISS) -> str:
    retriever = vectorstore.as_retriever(
        search_kwargs={
            "k": 1,
            "score_threshold": 0.7
        }
    )

    # Formulate search query based on user input
    search_query = f"{user_input['content_categories']} {user_input['genders']} ì¸í”Œë£¨ì–¸ì„œ"
    # Retrieve the document
    retrieved_docs = retriever.invoke(search_query)
    # Process the result
    influencer_examples = ""
    for idx, doc in enumerate(retrieved_docs, 1):
        content = doc.page_content
        influencer_examples += f"{content}\n\n"

    return influencer_examples

class GrowthStrategyRepositoryImpl(GrowthStrategyRepository):
    __instance = None

    def __new__(cls):
        if cls.__instance is None:
            cls.__instance = super().__new__(cls)

        return cls.__instance

    @classmethod
    def getInstance(cls):
        if cls.__instance is None:
            cls.__instance = cls()

        return cls.__instance

    async def fetch_growth_strategy(self, content_categories, ages, genders, visibility, platforms, investment_amount, upload_frequency, interested_influencer, userToken, request_id):
        user_input = {
            "genders": genders,
            "ages": ages,
            "content_categories": content_categories,
            "upload_frequency": upload_frequency,
            "investment_amount": investment_amount,
            "visibility": visibility,
            "platforms": platforms,
            "interested_influencer": "None"
        }

        prompt = PromptTemplate.from_template("""
        user_input :
        ì»¨í…ì¸  : {content_categories}
        ë‚˜ì´ëŒ€: {ages}
        ì„±ë³„: {genders}
        ê³µê°œ ì •ë„: {visibility}
        í”Œë«í¼: {platforms}
        íˆ¬ì ê°€ëŠ¥ ê¸ˆì•¡: {investment_amount}
        ì—…ë¡œë“œ ê°€ëŠ¥ ì£¼ê¸°: {upload_frequency}
        ê´€ì‹¬ ìˆëŠ” ì¸í”Œë£¨ì–¸ì„œ: {interested_influencer}
        ì¶”ì²œ ì¸í”Œë£¨ì–¸ì„œ : {recommended_influencer}

        ref:
        ### ì…ë ¥ ìš”ì•½ - {{ì»¨í…ì¸ }}: ë·°í‹° - {{ë‚˜ì´ëŒ€}}: 10ëŒ€ - {{ì„±ë³„}}: ë‚¨ì - {{ê³µê°œ ì •ë„}}: ì–¼êµ´ ê³µê°œ - {{í”Œë«í¼}}: YouTube - {{íˆ¬ì ê°€ëŠ¥ ê¸ˆì•¡}}: ì—†ë‹¤ - {{ì—…ë¡œë“œ ê°€ëŠ¥ ì£¼ê¸°}}: ë§¤ì¼ - {{ê´€ì‹¬ ìˆëŠ” ì¸í”Œë£¨ì–¸ì„œ}}: ë ˆì˜¤ì œì´

        ### ì…ë ¥ ë¶„ì„
        ì¥ì :
        - {{ë‚˜ì´ëŒ€}} {{ì„±ë³„}}ì´ {{ì»¨í…ì¸ }}ì— ë„ì „í•˜ëŠ” ê²ƒì€ ë¹„êµì  ìœ ë‹ˆí¬í•œ í¬ì§€ì…”ë‹ì…ë‹ˆë‹¤. ê¸°ì¡´ì˜ ì—¬ì„± ì¤‘ì‹¬ {{ì½˜í…ì¸ }} ì‹œì¥ì—ì„œ ìƒˆë¡œìš´ íŠ¸ë Œë“œì™€ ë‹¤ì–‘ì„±ì„ ë³´ì—¬ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        - {{ê³µê°œ ì •ë„}}ë¡œ ì‹œì²­ìì™€ ë” ê¹Šì´ ì†Œí†µí•  ìˆ˜ ìˆìœ¼ë©°, ì¹œê·¼í•˜ê³  ì‹ ë¢°ê° ìˆëŠ” ì´ë¯¸ì§€ë¥¼ êµ¬ì¶•í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        - {{ì—…ë¡œë“œ ê°€ëŠ¥ ì£¼ê¸°}} ì—…ë¡œë“œí•˜ëŠ” ì¼ì •í•œ ì½˜í…ì¸  íë¦„ì€ {{í”Œë«í¼}} ì•Œê³ ë¦¬ì¦˜ ìƒ ë…¸ì¶œ ë¹ˆë„ë¥¼ ë†’ì´ê³ , êµ¬ë…ìì™€ì˜ ì¼ê´€ëœ ì†Œí†µì—ë„ ìœ ë¦¬í•©ë‹ˆë‹¤.

        ë‹¨ì :
        - {{ì½˜í…ì¸ }}ì— ëŒ€í•œ ê³ ì •ê´€ë…ìœ¼ë¡œ ì¸í•œ ë¶€ì •ì ì¸ ë°˜ì‘ì´ ìˆì„ ìˆ˜ ìˆìœ¼ë‚˜, ìì‹ ê° ìˆëŠ” íƒœë„ê°€ í•„ìš”í•©ë‹ˆë‹¤.
        - {{íˆ¬ì ê°€ëŠ¥ ê¸ˆì•¡}}ì˜ ìƒí™©ì—ì„œëŠ” ê³ ê°€ì˜ ì œí’ˆ ëŒ€ì‹  í•™ìƒë“¤ì—ê²Œ ë§ëŠ” ê¸°ì´ˆ ìŠ¤í‚¨ì¼€ì–´ì™€ ì €ë ´í•œ í™”ì¥í’ˆ ë¦¬ë·°ë¡œ ì‹œì‘í•´ì•¼ í•©ë‹ˆë‹¤.
        - {{ì—…ë¡œë“œ ê°€ëŠ¥ ì£¼ê¸°}} ì—…ë¡œë“œëŠ” ì²´ë ¥ì ìœ¼ë¡œ ë¶€ë‹´ì´ ë  ìˆ˜ ìˆìœ¼ë‹ˆ, ìˆí¼ ì½˜í…ì¸ ë¥¼ í™œìš©í•´ íš¨ìœ¨ì„±ì„ ë†’ì…ë‹ˆë‹¤.

        ---

        ### ì¸í”Œë£¨ì–¸ì„œ ë¶„ì„: {{ì¶”ì²œ ì¸í”Œë£¨ì–¸ì„œ}}
        - {{ì¶”ì²œ ì¸í”Œë£¨ì–¸ì„œ}}ëŠ” {{ì½˜í…ì¸ }} ìœ íŠœë²„ë¡œì„œ ì¬ì¹˜ ìˆëŠ” ì§„í–‰ê³¼ ì¹´ë¦¬ìŠ¤ë§ˆ ìˆëŠ” ë©”ì´í¬ì—… ìŠ¤íƒ€ì¼ë¡œ ì¸ê¸°ë¥¼ ëŒê³  ìˆìŠµë‹ˆë‹¤.
        - ë‹¤ì–‘í•œ {{ì½˜í…ì¸ }} ì½˜í…ì¸ (ë©”ì´í¬ì—… íŠœí† ë¦¬ì–¼, ì¼ìƒ ë¸Œì´ë¡œê·¸)ë¥¼ í†µí•´ ì‹œì²­ìì™€ ì¹œê·¼í•˜ê²Œ ì†Œí†µí•˜ë©°, ìì‹ ì˜ ìŠ¤íƒ€ì¼ì„ í™•ê³ í•˜ê²Œ ìœ ì§€í•œ ê²ƒì´ ì„±ê³µ ìš”ì¸ì…ë‹ˆë‹¤.

        ì ìš© ì „ëµ:
        - {{ì¶”ì²œ ì¸í”Œë£¨ì–¸ì„œ}}ì²˜ëŸ¼ ìºë¦­í„°ì™€ ìì‹ ê° ìˆëŠ” íƒœë„ë¥¼ ìœ ì§€í•˜ë©° ì‹œì²­ìì™€ ì†Œí†µí•˜ì„¸ìš”.
        - ì´ˆê¸°ì—ëŠ” ê°„ë‹¨í•œ í•™ìƒìš© ìŠ¤í‚¨ì¼€ì–´ íŒì´ë‚˜ ì €ê°€ ë©”ì´í¬ì—… íŠœí† ë¦¬ì–¼ë¡œ ì‹œì‘í•˜ê³ , ì ì°¨ ë³¸ì¸ë§Œì˜ {{ì½˜í…ì¸ }} ìŠ¤íƒ€ì¼ì„ ì°¾ì•„ê°€ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.
        - {{ì¶”ì²œ ì¸í”Œë£¨ì–¸ì„œ}}ì²˜ëŸ¼ ìœ ë¨¸ì™€ ìŠ¤í† ë¦¬í…”ë§ì„ ë”í•´ ì‹œì²­ìì™€ ì¹œë°€ê°ì„ ìŒ“ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤.

        ---

        ### ì½˜í…ì¸  ì „ëµ
        1. ê¸°ì´ˆ ìŠ¤í‚¨ì¼€ì–´ ë° ì €ì˜ˆì‚° í™”ì¥í’ˆ ë¦¬ë·°
           - í•™ìƒë“¤ì—ê²Œ ë§ëŠ” ì €ë ´í•œ ìŠ¤í‚¨ì¼€ì–´ ì œí’ˆ ë¦¬ë·°ì™€ ì—¬ë“œë¦„ ê´€ë¦¬ë²•ì„ ì†Œê°œí•©ë‹ˆë‹¤.
           - â€œ10ëŒ€ê°€ ê¼­ ì•Œì•„ì•¼ í•  {{ì½˜í…ì¸ }} ê¿€íŒâ€ê³¼ ê°™ì€ íƒ€ì´í‹€ë¡œ ì‹œì²­ìë“¤ì˜ ê´€ì‹¬ì„ ìœ ë„í•©ë‹ˆë‹¤.

        2. ë°ì¼ë¦¬ ë©”ì´í¬ì—… ì±Œë¦°ì§€
           - ì¼ì£¼ì¼ ë™ì•ˆ ë§¤ì¼ ë‹¤ë¥¸ í…Œë§ˆë¡œ ë©”ì´í¬ì—…ì„ ì‹œë„í•˜ëŠ” ì±Œë¦°ì§€ ì½˜í…ì¸ ë¥¼ ê¸°íší•©ë‹ˆë‹¤.
           - ì˜ˆ: "í•™êµ ê°€ê¸° ì „ 5ë¶„ ë©”ì´í¬ì—…," "K-íŒ ì•„ì´ëŒ ë£© ë„ì „í•˜ê¸°."

        3. {{ì½˜í…ì¸ }} ê´€ë ¨ ë¸Œì´ë¡œê·¸
           - ìì‹ ì˜ ì¼ìƒ ì†ì—ì„œ í™”ì¥í’ˆì„ ì‚¬ìš©í•˜ëŠ” ëª¨ìŠµì„ ë‹´ì€ ë¸Œì´ë¡œê·¸ë¥¼ í†µí•´ ì¹œê·¼í•œ ì´ë¯¸ì§€ë¥¼ êµ¬ì¶•í•©ë‹ˆë‹¤.
           - "í™”ì¥í’ˆ êµ¬ë§¤ ë¸Œì´ë¡œê·¸" ë˜ëŠ” "ë©”ì´í¬ì—… ì‹¤ìŠµì¼ê¸°"ì™€ ê°™ì€ ì½˜í…ì¸ ê°€ ìœ íš¨í•©ë‹ˆë‹¤.

        4. ìœ ë¨¸ì™€ ìŠ¤í† ë¦¬í…”ë§ í™œìš©
           - {{ì¶”ì²œ ì¸í”Œë£¨ì–¸ì„œ}}ì²˜ëŸ¼ ì¬ë¯¸ìˆëŠ” ì¼í™”ë‚˜ ì—í”¼ì†Œë“œë¥¼ ê³ë“¤ì—¬ ì½˜í…ì¸ ë¥¼ ë§Œë“­ë‹ˆë‹¤. ì‹œì²­ìë“¤ì´ ì‰½ê²Œ ê³µê°í•  ìˆ˜ ìˆë„ë¡ ìœ ë¨¸ëŸ¬ìŠ¤í•œ ì§„í–‰ì„ ì‹œë„í•´ë³´ì„¸ìš”.

        ---

        ### ì˜ˆì‚°ë³„ ì¥ë¹„ ë° íˆ´ ì¶”ì²œ
        - {{íˆ¬ì ê°€ëŠ¥ ê¸ˆì•¡}}ì— ë§ëŠ” ì¥ë¹„ë“¤ì„ ì¶”ì²œí•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´ ìš´ë™ë§¤íŠ¸ - 5ë§Œì›

        ---

        ### ì´ì •ë¦¬: ì„±ì¥ ë¡œë“œë§µ
        1. 1~2ê°œì›”: ì €ì˜ˆì‚° ìŠ¤í‚¨ì¼€ì–´ ë° ë©”ì´í¬ì—… ì œí’ˆ ë¦¬ë·°ë¡œ ì‹œì‘í•˜ì—¬ êµ¬ë…ì ê¸°ë°˜ì„ ë‹¤ì§‘ë‹ˆë‹¤.
        2. 3~6ê°œì›”: {{ì—…ë¡œë“œ ê°€ëŠ¥ ì£¼ê¸°}} ì—…ë¡œë“œë¥¼ ìœ ì§€í•˜ë©°, ë‹¤ì–‘í•œ ë©”ì´í¬ì—… ì±Œë¦°ì§€ì— ë„ì „í•©ë‹ˆë‹¤.
        3. 6ê°œì›”~1ë…„: ëŒ“ê¸€ê³¼ ë¼ì´ë¸Œ ë°©ì†¡ì„ í™œìš©í•´ ì†Œí†µì„ ê°•í™”í•˜ê³ , ìƒˆë¡œìš´ íŠ¸ë Œë“œì™€ í˜‘ì—… ê¸°íšŒë¥¼ ëª¨ìƒ‰í•©ë‹ˆë‹¤.
        4. 1ë…„ í›„: ë³¸ì¸ë§Œì˜ {{ì½˜í…ì¸ }} ìŠ¤íƒ€ì¼ì„ í™•ë¦½í•˜ê³ , ë‹¤ë¥¸ {{í”Œë«í¼}} ì¸í”Œë£¨ì–¸ì„œì™€ì˜ ì½œë¼ë³´ ì½˜í…ì¸ ë¡œ ìƒˆë¡œìš´ íŒ¬ì¸µì„ ìœ ì…ì‹œí‚µë‹ˆë‹¤.

        ---

        ### ì‘ì› ë©”ì‹œì§€ ğŸ‰
        {{ì½˜í…ì¸ }} ìœ íŠœë²„ì˜ ê¸¸ì— ë„ì „í•˜ëŠ” ë‹¹ì‹ ì„ ì‘ì›í•©ë‹ˆë‹¤! {{ê´€ì‹¬ ìˆëŠ” ì¸í”Œë£¨ì–¸ì„œ}}ì²˜ëŸ¼ ìì‹ ê° ìˆëŠ” íƒœë„ë¡œ ìƒˆë¡œìš´ {{ì½˜í…ì¸ }} íŠ¸ë Œë“œë¥¼ ì´ëŒì–´ê°€ì„¸ìš”. ê¾¸ì¤€í•œ ë…¸ë ¥ê³¼ ì§„ì†”í•œ ì†Œí†µì´ ë‹¹ì‹ ì˜ ê°€ì¥ í° ë¬´ê¸°ê°€ ë  ê²ƒì…ë‹ˆë‹¤. ë‹¹ì‹ ì˜ ì„±ì¥ì´ ê³§ {{ë‚˜ì´ëŒ€}} {{ì„±ë³„}} {{ì½˜í…ì¸ }} ì‹œì¥ì˜ ìƒˆë¡œìš´ ê¸°ì¤€ì´ ë  ê±°ì˜ˆìš”!
        """)

        try:
            # ë‹¨ê³„ 1: ë¬¸ì„œ ë¡œë“œ(Load Documents)
            # í˜„ì¬ ì‘ì—… ë””ë ‰í„°ë¦¬ ê²½ë¡œë¥¼ ì–»ê¸°
            current_dir = os.getcwd()
            file_path = os.path.join(current_dir, "data", "summarized_youtuber_data.json")

            json_data = load_json_data(file_path)

            # JSON ë°ì´í„°ë¥¼ Document í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            documents = [
                Document(
                    page_content=item["features"],  # ë¬¸ì„œ ë‚´ìš©ì€ features ì†ì„±ì—ì„œ ê°€ì ¸ì˜µë‹ˆë‹¤.
                    metadata={"name": item["name"]}  # ë©”íƒ€ë°ì´í„°ì— name ì†ì„±ì„ ì¶”ê°€í•©ë‹ˆë‹¤.
                )
                for item in json_data  # docsëŠ” JSON ë°ì´í„°ë¥¼ ë¡œë“œí•œ ê²°ê³¼ì…ë‹ˆë‹¤.
            ]

            # ë‹¨ê³„ 3: ì„ë² ë”©(Embedding) ìƒì„±
            embeddings = OpenAIEmbeddings()

            # ë‹¨ê³„ 4: DB ìƒì„±(Create DB) ë° ì €ì¥
            vectorstore = FAISS.from_documents(documents=documents, embedding=embeddings)

            # ë‹¨ê³„ 5: ê²€ìƒ‰ê¸° ìƒì„±
            recommended_influencer = get_relevant_influencers(user_input, vectorstore)
            print("ì¶”ì²œ ì¸í”Œë£¨ì–¸ì„œ :", recommended_influencer)

            # ë‹¨ê³„ 7: LLM ëª¨ë¸ ìƒì„± (call backí•¨ìˆ˜ ë“±ë¡)
            llm = ChatOpenAI(model_name="gpt-4o-mini", temperature=0, callbacks=[MyCustomAsyncHandler()])

            # ë‹¨ê³„ 8: ì²´ì¸ ìƒì„±
            question = ("chainì„ ì‹¤í–‰í•˜ë©´ì„œ refì— ëŒ€í•œ ëª¨ë“  ì„¸ë¶€ ë‚´ìš©ë“¤ì— ëŒ€í•´ ë‹¨ê³„ ë³„ë¡œ ìƒê°í•˜ê³  ìƒê°í•œ ê²ƒì— ëŒ€í•´ ê·¸ëŒ€ë¡œ ë‹µë³€ì„ í•´ì¤˜. êµ¬ì²´ì ì¼ìˆ˜ë¡ ì¢‹ì•„"
                        "ì˜ˆë¥¼ ë“¤ì–´ '~~ê°€ ê¼­ ì•Œì•„ì•¼ í•  ~~ê¿€íŒ' íƒ€ì´í‹€ì˜ ì»¨í…ì¸  ë‚´ìš©ì€ ì–´ë–»ê²Œ êµ¬ì„±í•´ì•¼ í•˜ëŠ”ì§€ë¥¼ ì•Œë ¤ì£¼ëŠ” ë°©ì‹ìœ¼ë¡œ í•´ì¤˜."
                        "ìœ„ì˜ ë°©ì‹ìœ¼ë¡œ ê° ì†Œì œëª© ë§ˆë‹¤ ì „ëµì„ 5ê°€ì§€ ì œì‹œí•´ì¤˜."
                        "ê·¸ë¦¬ê³  ê° êµ¬ì²´ì ì¸ ë‚´ìš©ë“¤ì— ëŒ€í•´ì„œëŠ” bullet pointë§ê³  ìˆ«ìë¡œë§Œ êµ¬ë¶„í•´ì¤˜.")

            # ì‚¬ìš©ì ì…ë ¥ ë³€ìˆ˜ë¥¼ ë„£ìœ¼ë ¤ë©´ lambda _: ì˜ í˜•íƒœë¡œ ë°›ì•„ì¤˜ì•¼í•¨
            chain = (
                    {"recommended_influencer": lambda _: recommended_influencer, "question": lambda _: question,
                     "genders": lambda _: genders, "ages": lambda _: ages,
                     "content_categories": lambda _: content_categories, "upload_frequency": lambda _: upload_frequency,
                     "investment_amount": lambda _: investment_amount, "visibility": lambda _: visibility,
                     "platforms": lambda _: platforms, "interested_influencer": lambda _: interested_influencer,
                     }
                    | prompt
                    | llm
                    | StrOutputParser()
            )
            # ë‹¨ê³„ 9: ì²´ì¸ ì‹¤í–‰
            strategy = chain.invoke(question) # ì—¬ê¸°ì„œ ì—ëŸ¬ í„°ì§
            print(strategy)
            return {"generatedText": strategy, "userToken": userToken, "request_id": request_id}  # dict í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•´ì£¼ì–´ì•¼ í•¨
        except Exception as e:
            return f"ì˜¤ë¥˜ ë°œìƒ: {e}"

